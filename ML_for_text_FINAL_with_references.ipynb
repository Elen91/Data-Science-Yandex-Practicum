{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#План-работы\" data-toc-modified-id=\"План-работы-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>План работы</a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-данных-и-подключение-библиотек\" data-toc-modified-id=\"Загрузка-данных-и-подключение-библиотек-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Загрузка данных и подключение библиотек</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Машинное-обучение-без-нейросети.-Логистическая-регрессия\" data-toc-modified-id=\"Машинное-обучение-без-нейросети.-Логистическая-регрессия-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Машинное обучение без нейросети. Логистическая регрессия</a></span><ul class=\"toc-item\"><li><span><a href=\"#Предобработка-данных\" data-toc-modified-id=\"Предобработка-данных-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Предобработка данных</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#XGBClassifier\" data-toc-modified-id=\"XGBClassifier-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>XGBClassifier</a></span></li><li><span><a href=\"#SGDClassifier\" data-toc-modified-id=\"SGDClassifier-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>SGDClassifier</a></span></li><li><span><a href=\"#Общий-вывод\" data-toc-modified-id=\"Общий-вывод-2.1.5\"><span class=\"toc-item-num\">2.1.5&nbsp;&nbsp;</span>Общий вывод</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества `F1` не меньше `0.75`. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять `BERT` необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`.  \n",
    "\n",
    "Столбец `text`  — в нём содержит текст комментария, а `toxic` — целевой признак.\n",
    "\n",
    "\n",
    "### План работы\n",
    "\n",
    "1. Проведу предварительную обработку данных\n",
    "2. Обучу несколько моделей и протестирую их. Сначала проведу обучению без нейросетки, а затем применю BERT.\n",
    "3. Сравню метрику качества `f1` (должен быть не меньше `0.75`).\n",
    "4. Сделаю выводы. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка\n",
    "\n",
    "### Загрузка данных и подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torch\n",
    "#%pip install tensorflow # установилась с 1 ошибкой\n",
    "#%pip install transformers\n",
    "#%pip install pymystem3\n",
    "#%pip install textblob\n",
    "#%pip install xgboost\n",
    "#%pip install bert-for-tf2\n",
    "#%pip install sentencepiece\n",
    "#%pip install tensorflow\n",
    "#%pip install tensorflow_hub\n",
    "\n",
    "#%matplotlib inline\n",
    "#%pip install scikit-learn --user --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update sklearn\n",
    "#%pip install --upgrade sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from torch import cuda\n",
    "from torch import Tensor\n",
    "\n",
    "import nltk # Natural Language Toolkit, «инструментарий естественного языка»\n",
    "from nltk.corpus import stopwords as nltk_stopwords # корпус топ-слов\n",
    "from sklearn.feature_extraction.text import CountVectorizer # счётчик слов для создания векторов\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # счётчик величин TF-IDF \n",
    "#from pymystem3 import Mystem # для лемматизации русских слов\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from textblob import TextBlob, Word\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# для BERT\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# импорт метрики качества \n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
    "\n",
    "# импорт моделей \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from catboost import CatBoostClassifier\n",
    "#from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "#from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#КОД РЕВЬЮЕРА\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import HalvingRandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\eabdurakhmanova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\eabdurakhmanova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\eabdurakhmanova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\eabdurakhmanova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# скачаем стоп-слова\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтение данных\n",
    "try:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    data = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Краткий вывод** \n",
    "\n",
    "В данных два столбца: \n",
    "- `text` с комментариями (на английском языке)\n",
    "- `toxic` с метками является ли комментарий позитивным (1) или нет (0). \n",
    "\n",
    "Данные полные без пропусков. \n",
    "\n",
    "## Обучение\n",
    "\n",
    "### Машинное обучение без нейросети. Логистическая регрессия \n",
    "\n",
    "Обучу логистическую регрессию определять тональность текста. \n",
    "\n",
    "Разделю выборку на тренировочную и тестовую. \n",
    "\n",
    "Сначала лемматизирую тексты. Затем подсчитаю величину `TF-IDF` (оценим важность слов) для текстов. \n",
    "\n",
    "Обучу логистическую регрессию определять результаты предсказания для тестовой выборки комментариев.\n",
    "\n",
    "Найду значение `f1-score`, которое должно быть не меньше `0.75`. \n",
    "\n",
    "#### Предобработка данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# очистка текста от лишних символов\n",
    "# код взят отсюда https://stackabuse.com/text-classification-with-bert-tokenizer-and-tf-2-0-in-python/\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['text'] = data['text'].apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 159571/159571 [00:13<00:00, 12052.22it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(4) as p:\n",
    "        data['text'] = data['text'].progress_apply(preprocess_text) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделение выборки на обучающую и тестовую\n",
    "state = np.random.RandomState(12345)\n",
    "\n",
    "features = data['text']\n",
    "target = data['toxic']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state=state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код ниже я нашла по ссылке https://webdevblog.ru/podhody-lemmatizacii-s-primerami-v-python/ \n",
    "\n",
    "Функция ниже нужна для того, чтобы лемматизация проходила корректно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_with_postag(sentence):\n",
    "    sent = TextBlob(sentence)\n",
    "    tag_dict = {\"J\": 'a', \n",
    "                \"N\": 'n', \n",
    "                \"V\": 'v', \n",
    "                \"R\": 'r'}\n",
    "    words_and_tags = [(w, tag_dict.get(pos[0], 'n')) for w, pos in sent.tags]    \n",
    "    lemmatized_list = [wd.lemmatize(tag) for wd, tag in words_and_tags]\n",
    "    return \" \".join(lemmatized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 111699/111699 [10:26<00:00, 178.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Lemmatize\n",
    "#lemmatized_output = X_train.apply(lambda x: lemmatize_with_postag(x))\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(32) as p:\n",
    "        lemmatized_output = X_train.progress_apply(lemmatize_with_postag) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5982      think Access Denied be perfectly valid usernam...\n",
       "155963    Please stop abuse the word hopefully Ignorant ...\n",
       "57212     Progressive Dance music see you don surrender ...\n",
       "125660    Japanese character They annoy me this be an en...\n",
       "105510    Yeah it do seem kind of over and just to let y...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 47872/47872 [04:32<00:00, 175.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# создадим корпус лемм для тестовой выборки\n",
    "#lemmatized_output_test = X_test.apply(lambda x: lemmatize_with_postag(x))\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(32) as p:\n",
    "        lemmatized_output_test = X_test.progress_apply(lemmatize_with_postag) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (111699, 130550)\n",
      "Размер матрицы: (47872, 130550)\n"
     ]
    }
   ],
   "source": [
    "# создам матрицу cо значениями TF-IDF по корпусу твитов\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords) \n",
    "tf_idf_fit = count_tf_idf.fit(lemmatized_output) # матрица\n",
    "tf_idf = tf_idf_fit.transform(lemmatized_output)\n",
    "tf_idf_test = tf_idf_fit.transform(lemmatized_output_test) # берем count_tf_idf с обучающей выборки\n",
    "\n",
    "# выводим размеры матрицы\n",
    "print(\"Размер матрицы:\", tf_idf.shape)\n",
    "print(\"Размер матрицы:\", tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "tf_idf[:10].todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну что ж... ))) Данные для анализа готовы. Перейдем к обучению моделей.\n",
    "\n",
    "Здесь я обучу 3 модели:\n",
    "- логистическую регрессию\n",
    "- XGBClassifier\n",
    "- SGDClassifier\n",
    "\n",
    "Я также рассматривала модели GradientBoostingClassifier, CatBoostClassifier и LGBMClassifier, но они очень долго считались. Не стала использовать их в проекте \n",
    "\n",
    "Сравню время обучения, предсказания и качество метрики `f1-score`. \n",
    "\n",
    "\n",
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score для тренировочной выборки равен 0.8300341296928329\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "logistic_model = LogisticRegression(random_state=state, \n",
    "                        class_weight=\"balanced\")\n",
    "\n",
    "logistic_model.fit(tf_idf, y_train)\n",
    "target_predicted = logistic_model.predict(tf_idf)\n",
    "\n",
    "print(\"F1-score для тренировочной выборки равен\", f1_score(y_train, target_predicted))\n",
    "\n",
    "logistic_model_fit_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score на кросс-валидации равен 0.7435195893621628\n",
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Проверим качество модели на кросс-валидации\n",
    "cv_f1_logistic_model = (cross_val_score(logistic_model, \n",
    "                             tf_idf, \n",
    "                             y_train, \n",
    "                             cv=5, \n",
    "                             n_jobs=4,\n",
    "                             scoring='f1').mean())\n",
    "print('F1-score на кросс-валидации равен', cv_f1_logistic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score для тестовой выборки равен 0.7451858486341244\n"
     ]
    }
   ],
   "source": [
    "# время предсказания\n",
    "start_time = time.time()\n",
    "\n",
    "target_test_predicted = logistic_model.predict(tf_idf_test)\n",
    "logistic_model_test_f1 = f1_score(y_test, target_test_predicted)\n",
    "\n",
    "print(\"F1-score для тестовой выборки равен\", logistic_model_test_f1)\n",
    "\n",
    "logistic_model_predicted_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Краткий вывод** \n",
    "\n",
    "Наша модель переобучилась на тренировочных данных. Но кросс-валидация спасает ситуацию.`F1-score` на кросс-валидации и на тестовой выборке примерно одинаковые. И мы практически достигли цели, но `f1-score` немного меньше `0.75`. Попробуем подобрать гиперпараметры для логистической регресси и проверим измениться ли качество метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры для логистической регресси LogisticRegression(C=10, class_weight='balanced',\n",
      "                   random_state=RandomState(MT19937) at 0x2407290FE40)\n",
      "Лучший показатель f1-score 0.7612000441938818\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = parameters = {'C': [3, 5, 10],\n",
    "                           'class_weight':['balanced', None]}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=state)\n",
    "\n",
    "# заменила GridSearchCV \n",
    "grid_search = RandomizedSearchCV(logistic_model, \n",
    "                           parameters, \n",
    "                           n_jobs=4, \n",
    "                           scoring=\"f1\", \n",
    "                           cv=skf) # cv=skf\n",
    "grid_search = grid_search.fit(tf_idf, y_train)\n",
    "print('Лучшие гиперпараметры для логистической регресси', grid_search.best_estimator_)\n",
    "print('Лучший показатель f1-score', grid_search.best_score_)\n",
    "\n",
    "f1_grid_search = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score для тестовой выборки равен 0.7577992058990358\n"
     ]
    }
   ],
   "source": [
    "# время предсказания\n",
    "start_time = time.time()\n",
    "\n",
    "target_test_predicted = grid_search.predict(tf_idf_test)\n",
    "logistic_model_test_f1 = f1_score(y_test, target_test_predicted)\n",
    "\n",
    "print(\"F1-score для тестовой выборки равен\", logistic_model_test_f1)\n",
    "\n",
    "logistic_model_predicted_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Краткий вывод**\n",
    "\n",
    "Круто! При подборе гиперпараметра `C` удалось повысить качество модели. `F1-score` не меньше `0.75`. \n",
    "\n",
    "Обучим некоторые более сложные модели и оценим метрику для них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Wall time: 1h 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# время обучения\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
    "    ('logreg', LogisticRegression(random_state=state)),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.5, 0.75), # удаляем очень частые слова\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)], # для N-грамм\n",
    "    'logreg__C': (0.0001, 0.001, 0.01, 0.1, 1, 10),\n",
    "    'logreg__class_weight':['balanced', None]\n",
    "}\n",
    "\n",
    "# Изменения \n",
    "grid_search_tune = RandomizedSearchCV(pipeline, \n",
    "                                      parameters, \n",
    "                                      cv=skf, \n",
    "                                      n_jobs=4, \n",
    "                                      scoring='f1', \n",
    "                                      verbose=3)\n",
    "\n",
    "grid_search_tune.fit(lemmatized_output, y_train)\n",
    "\n",
    "grid_search_tune_fit_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__ngram_range': (1, 3),\n",
       " 'tfidf__max_df': 0.75,\n",
       " 'logreg__class_weight': None,\n",
       " 'logreg__C': 10}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_tune.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76312075781823\n"
     ]
    }
   ],
   "source": [
    "cv_f1_logistic_model = grid_search_tune.best_score_\n",
    "print(cv_f1_logistic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score для тестовой выборки равен 0.7789379140002246\n",
      "Wall time: 17.6 s\n",
      "Parser   : 149 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# время предсказания\n",
    "start_time = time.time()\n",
    "grid_search_tune_test_pred = grid_search_tune.predict(lemmatized_output_test)\n",
    "\n",
    "grid_search_tune_test_f1 = f1_score(y_test, grid_search_tune_test_pred)\n",
    "\n",
    "print(\"F1-score для тестовой выборки равен\", grid_search_tune_test_f1)\n",
    "\n",
    "grid_search_tune_predicted_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Краткий вывод** \n",
    "\n",
    "Обучение проходит сравнительно недолго. \n",
    "Качество модели улучшилось, на тестовой выборке `f1-score` = `0.77`. И оно сопоставимо с результатом, где логистическая модель с гиперпараметрами обучалась без pipeline.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score для тренировочной выборки равен 0.71847553388331\n",
      "Wall time: 31min 19s\n",
      "Parser   : 576 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "start_time = time.time()\n",
    "xgb_cl = XGBClassifier()\n",
    "\n",
    "# подберем гиперпараметры \n",
    "params_xgb = {\n",
    "    'max_depth': range (2, 10, 2),\n",
    "    'n_estimators': range(50, 100, 10),\n",
    "    #'learning_rate': [0.1, 0.01, 0.05] # уменьшила число подбираемых гиперпараметров, потому что долго считалось\n",
    "}\n",
    "\n",
    "# заменила GridSearchCV \n",
    "xgb_cl_gsc = RandomizedSearchCV(xgb_cl, \n",
    "                            params_xgb, \n",
    "                           n_jobs=4, \n",
    "                           scoring=\"f1\", \n",
    "                           cv=skf)\n",
    "\n",
    "xgb_cl_gsc = xgb_cl_gsc.fit(tf_idf, y_train)\n",
    "\n",
    "cv_f1_xgb_model = xgb_cl_gsc.best_score_\n",
    "\n",
    "print(\"F1-score для тренировочной выборки равен\", cv_f1_xgb_model)\n",
    "\n",
    "xgb_cl_fit_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score для тестовой выборки равен 0.7304432065875515\n"
     ]
    }
   ],
   "source": [
    "# время предсказания \n",
    "start_time = time.time()\n",
    "\n",
    "target_xgb_cl_pred = xgb_cl_gsc.predict(tf_idf_test)\n",
    "target_xgb_cl_test_f1 = f1_score(y_test, target_xgb_cl_pred)\n",
    "\n",
    "print(\"F1-score для тестовой выборки равен\", target_xgb_cl_test_f1)\n",
    "\n",
    "xgb_cl_predicted_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Краткий вывод** \n",
    "\n",
    "Без кросс-валидации модель переобучилась, `f1-score` сильно выше, чем на тестовой выборке. Результаты кросс-валидации и на тестовой выборке примерно одинаковые. Но `f1-score` не достигает нужного значения и ниже, чем результат логистической регрессии. Перейдем к следующей модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Wall time: 12min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "sgd_pipeline = Pipeline([\n",
    "               ('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
    "               ('clf', SGDClassifier(random_state=12345))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.5, 0.75), # удаляем очень частые слова\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)], # для N-грамм\n",
    "    'clf__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'clf__class_weight': ['balanced', None],\n",
    "    'clf__alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "\n",
    "gs_clf = RandomizedSearchCV(sgd_pipeline, \n",
    "                            parameters,\n",
    "                            cv=skf, \n",
    "                            n_jobs=4, \n",
    "                            scoring='f1',\n",
    "                            verbose=3,\n",
    "                            random_state = 12345)\n",
    "\n",
    "gs_clf = gs_clf.fit(lemmatized_output, y_train)\n",
    "\n",
    "sgd_cl_fit_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6106084872361416\n"
     ]
    }
   ],
   "source": [
    "cv_f1_sgd_cl_model = gs_clf.best_score_\n",
    "print(cv_f1_sgd_cl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score для тестовой выборки равен 0.6181573638197713\n"
     ]
    }
   ],
   "source": [
    "# сохраним модель с лучшими параметрами и обучим её\n",
    "start_time = time.time()\n",
    "\n",
    "# проверим сколько времени требуется для предсказания и проверим качество модели на тестовой выборке\n",
    "target_sgd_pred = gs_clf.predict(lemmatized_output_test)\n",
    "\n",
    "sgd_cl_test_f1 = f1_score(y_test, target_sgd_pred)\n",
    "\n",
    "print(\"F1-score для тестовой выборки равен\", sgd_cl_test_f1)\n",
    "\n",
    "sgd_cl_model_predicted_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Краткий вывод**\n",
    "\n",
    "Как-то результаты ухудшились.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Общий вывод\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 на RandomizedSearchCV</th>\n",
       "      <th>F1 модели на тестовой выборке</th>\n",
       "      <th>Время обучения модели, сек</th>\n",
       "      <th>Время предсказания модели, сек</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression (pipeline)</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "      <td>3,699.52</td>\n",
       "      <td>17.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1,879.47</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>748.38</td>\n",
       "      <td>14.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               F1 на RandomizedSearchCV  \\\n",
       "LogisticRegression (pipeline)                      0.76   \n",
       "XGBClassifier                                      0.72   \n",
       "SGDClassifier                                      0.61   \n",
       "\n",
       "                               F1 модели на тестовой выборке  \\\n",
       "LogisticRegression (pipeline)                           0.78   \n",
       "XGBClassifier                                           0.73   \n",
       "SGDClassifier                                           0.62   \n",
       "\n",
       "                               Время обучения модели, сек  \\\n",
       "LogisticRegression (pipeline)                    3,699.52   \n",
       "XGBClassifier                                    1,879.47   \n",
       "SGDClassifier                                      748.38   \n",
       "\n",
       "                               Время предсказания модели, сек  \n",
       "LogisticRegression (pipeline)                           17.61  \n",
       "XGBClassifier                                            0.67  \n",
       "SGDClassifier                                           14.93  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "index = ['LogisticRegression (pipeline)',\n",
    "         'XGBClassifier',\n",
    "         'SGDClassifier']\n",
    "data_score = {'F1 на RandomizedSearchCV':[cv_f1_logistic_model,\n",
    "                                 cv_f1_xgb_model,\n",
    "                                 cv_f1_sgd_cl_model],\n",
    "        'F1 модели на тестовой выборке':[grid_search_tune_test_f1,\n",
    "                                         target_xgb_cl_test_f1,\n",
    "                                         sgd_cl_test_f1],\n",
    "        'Время обучения модели, сек':[grid_search_tune_fit_time,\n",
    "                                      xgb_cl_fit_time, \n",
    "                                      sgd_cl_fit_time],\n",
    "        'Время предсказания модели, сек':[grid_search_tune_predicted_time,\n",
    "                                          xgb_cl_predicted_time,\n",
    "                                          sgd_cl_model_predicted_time]}\n",
    "\n",
    "scores_data = pd.DataFrame(data=data_score, index=index)\n",
    "\n",
    "display(scores_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, логистическая регрессия показывает лучший результат. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках этого проекта была проведена классификация комментарии на позитивные и негативные. \n",
    "\n",
    "Для этого исходные тексты были очищены от несимвольных знаков, стоп-слов, проведена лемматизация и обучены три модели. Лучший показатель `f1-score` (`0.76`) был достигнут при помощи логистической регрессии.\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1204,
    "start_time": "2022-08-10T20:47:06.499Z"
   },
   {
    "duration": 2,
    "start_time": "2022-08-10T20:48:27.818Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
